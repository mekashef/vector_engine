{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJLQoimyVyQ8"
   },
   "source": [
    "### Uncomment and run the following cells if you work on Google Colab :) Don't forget to change your runtime type to GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVV81xc3VyQ9",
    "outputId": "5f91275b-3caf-4588-d4bd-ec11089b1b71"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/kstathou/vector_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0lSFLw3VyRG",
    "outputId": "ae5c260a-7925-4bc6-8aac-b6800017d1e0"
   },
   "outputs": [],
   "source": [
    "# cd vector_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5sOhWL6UVyRQ",
    "outputId": "e6f41a8c-d210-4b33-a1ac-4c3886253920"
   },
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbnscDwgVyRW"
   },
   "source": [
    "### Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v7ftrzzmVyRX"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fU2i4vlCVyRc"
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "# Used to import data from S3.\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "\n",
    "# Used to create the dense document vectors.\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Used to create and store the Faiss index.\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def vector_search(query, model, index, num_results=10):\n",
    "    \"\"\"Tranforms query to vector using a pretrained, sentence-level \n",
    "    DistilBERT model and finds similar vectors using FAISS.\n",
    "    Args:\n",
    "        query (str): User query that should be more than a sentence long.\n",
    "        model (sentence_transformers.SentenceTransformer.SentenceTransformer)\n",
    "        index (`numpy.ndarray`): FAISS index that needs to be deserialized.\n",
    "        num_results (int): Number of results to return.\n",
    "    Returns:\n",
    "        D (:obj:`numpy.array` of `float`): Distance between results and query.\n",
    "        I (:obj:`numpy.array` of `int`): Paper ID of the results.\n",
    "    \n",
    "    \"\"\"\n",
    "    vector = model.encode(list(query))\n",
    "    D, I = index.search(np.array(vector).astype(\"float32\"), k=num_results)\n",
    "    return D, I\n",
    "\n",
    "\n",
    "def id2details(df, I, column):\n",
    "    \"\"\"Returns the paper titles based on the paper index.\"\"\"\n",
    "    return [list(df[df.id == idx][column]) for idx in I[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz5YBwU5VyRi"
   },
   "source": [
    "Stored and processed data in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VEANywYAVyRi"
   },
   "outputs": [],
   "source": [
    "# Use pandas to read files from S3 buckets!\n",
    "df = pd.read_csv('../data/employee_dummy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "HJXljSbYVyRn",
    "outputId": "1c180fbc-42a4-441a-da47-14f5cc21d826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Skills', 'year', 'id'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MljadlGpVyRs",
    "outputId": "8f2f5205-772f-4c6b-f445-5dd32350d45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misinformation, disinformation and fake news papers: 299\n"
     ]
    }
   ],
   "source": [
    "print(f\"Misinformation, disinformation and fake news papers: {df.id.unique().shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyRG1wZLVyRw"
   },
   "source": [
    "The [Sentence Transformers library](https://github.com/UKPLab/sentence-transformers) offers pretrained transformers that produce SOTA sentence embeddings. Checkout this [spreadsheet](https://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/) with all the available models.\n",
    "\n",
    "In this tutorial, we will use the `distilbert-base-nli-stsb-mean-tokens` model which has the best performance on Semantic Textual Similarity tasks among the DistilBERT versions. Moreover, although it's slightly worse than BERT, it is quite faster thanks to having a smaller size.\n",
    "\n",
    "I use the same model in [Orion's semantic search engine](https://www.orion-search.org/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjF6CrwUVyRx",
    "outputId": "db338335-b032-45f2-db21-8e3f53640b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the sentence-level DistilBERT\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "# Check if GPU is available and use it\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(torch.device(\"cuda\"))\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "7a7e927567024c578b33b15000d5e531",
      "da5011a6565e45e2b5d0b37634498648",
      "3e9c24c8488b431fb88a0d045d85b700",
      "7aaf8a423e7f48bbac24d6970ed4dfe9",
      "f9c22552944b4e2dafe1f98170665293",
      "15c5bbc768db41e4bc06c9405539091c",
      "1e1408cddd284bc4a4b5484be0561991",
      "7f1cd9dbb4b742ab8d78e073fb9b0f90"
     ]
    },
    "id": "Y_GS0_CWVyR1",
    "outputId": "4deb0814-1ce9-4ea8-8e50-72992e0ea303"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e9e75f715e43f58e6405d6666c07dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Batches'), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert abstracts to vectors\n",
    "#df.Skills.to_list()[:301]\n",
    "embeddings = model.encode(df.Skills.to_list(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gE7w-RJbVyR6",
    "outputId": "0451849a-88ef-4aee-be2d-e6ff173782f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the vectorised abstract: (768,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the vectorised abstract: {embeddings[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGV4Je1EVyR_"
   },
   "source": [
    "## Vector similarity search with Faiss\n",
    "[Faiss](https://github.com/facebookresearch/faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, even ones that do not fit in RAM. \n",
    "    \n",
    "Faiss is built around the `Index` object which contains, and sometimes preprocesses, the searchable vectors. Faiss has a large collection of [indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes). You can even create [composite indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes-(composite)). Faiss handles collections of vectors of a fixed dimensionality d, typically a few 10s to 100s.\n",
    "\n",
    "**Note**: Faiss uses only 32-bit floating point matrices. This means that you will have to change the data type of the input before building the index.\n",
    "\n",
    "To learn more about Faiss, you can read their paper on [arXiv](https://arxiv.org/abs/1702.08734).\n",
    "\n",
    "Here, we will the `IndexFlatL2` index:\n",
    "- It's a simple index that performs a brute-force L2 distance search\n",
    "- It scales linearly. It will work fine with our data but you might want to try [faster indexes](https://github.com/facebookresearch/faiss/wiki/Faster-search) if you work will millions of vectors.\n",
    "\n",
    "To create an index with the `misinformation` abstract vectors, we will:\n",
    "1. Change the data type of the abstract vectors to float32.\n",
    "2. Build an index and pass it the dimension of the vectors it will operate on.\n",
    "3. Pass the index to IndexIDMap, an object that enables us to provide a custom list of IDs for the indexed vectors.\n",
    "4. Add the abstract vectors and their ID mapping to the index. In our case, we will map vectors to their paper IDs from MAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kkUDtwHVyR_",
    "outputId": "0f668d02-ef33-4123-ab77-18f72a93ab80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the Faiss index: 299\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Change data type\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
    "\n",
    "# Step 2: Instantiate the index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# Step 3: Pass the index to IndexIDMap\n",
    "index = faiss.IndexIDMap(index)\n",
    "\n",
    "# Step 4: Add vectors and their IDs\n",
    "index.add_with_ids(embeddings, df.id.values)\n",
    "\n",
    "print(f\"Number of vectors in the Faiss index: {index.ntotal}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt1z-433VySE"
   },
   "source": [
    "### Searching the index\n",
    "The index we built will perform a k-nearest-neighbour search. We have to provide the number of neighbours to be returned. \n",
    "\n",
    "Let's query the index with an abstract from our dataset and retrieve the 10 most relevant documents. **The first one must be our query!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "eEeJt7lYVySN",
    "outputId": "771571b3-0200-48b8-f2de-4e8cdbd5ec98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paper abstract\n",
    "df.iloc[200, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSuRcH85VySQ",
    "outputId": "cec93a12-e79c-4f0a-fc15-45048a3469aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "MAG paper IDs: [2156683801, 2012373852, 1999931407, 2124861983, 171007782, 2060919843, 2000297003, 1974143004, 1972193616, 2943415491]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 10 nearest neighbours\n",
    "D, I = index.search(np.array([embeddings[200]]), k=10)\n",
    "print(f'L2 distance: {D.flatten().tolist()}\\n\\nMAG paper IDs: {I.flatten().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiO1pa4oVySU",
    "outputId": "24c9d1ea-3951-4b4a-e436-c077f3528d7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the paper titles based on their index\n",
    "id2details(df, I, 'Skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p29pEtGrWUMV",
    "outputId": "b6448614-0a6a-4673-c841-2bfb0340607e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux'],\n",
       " ['Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the paper abstracts based on their index\n",
    "id2details(df, I, 'Skills')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFKvRb4QY-DL"
   },
   "source": [
    "\n",
    "## Putting all together\n",
    "\n",
    "So far, we've built a Faiss index using the misinformation abstract vectors we encoded with a sentence-DistilBERT model. That's helpful but in a real case scenario, we would have to work with unseen data. To query the index with an unseen query and retrieve its most relevant documents, we would have to do the following:\n",
    "\n",
    "1. Encode the query with the same sentence-DistilBERT model we used for the rest of the abstract vectors.\n",
    "2. Change its data type to float32.\n",
    "3. Search the index with the encoded query.\n",
    "\n",
    "Here, we will use the introduction of an article published on [HKS Misinformation Review](https://misinforeview.hks.harvard.edu/article/can-whatsapp-benefit-from-debunked-fact-checked-stories-to-reduce-misinformation/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iDhftkrhX99T"
   },
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "Golang  Python  C++  Java  JavaScript  C#  CSS     C  Docker  Keras  Numpy  Pandas  CI  Embedded Linux\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AFhbGnWZpWN",
    "outputId": "b8a02af0-2f0d-4740-984a-e804405b3e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance: [8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11, 8.13042827507715e-11]\n",
      "\n",
      "MAG paper IDs: [2156683801, 2012373852, 1999931407, 2124861983, 171007782, 2060919843, 2000297003, 1974143004, 1972193616, 2943415491]\n"
     ]
    }
   ],
   "source": [
    "# For convenience, I've wrapped all steps in the vector_search function.\n",
    "# It takes four arguments: \n",
    "# A query, the sentence-level transformer, the Faiss index and the number of requested results\n",
    "D, I = vector_search([user_query], model, index, num_results=10)\n",
    "print(f'L2 distance: {D.flatten().tolist()}\\n\\nMAG paper IDs: {I.flatten().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbanjBhBZtWZ",
    "outputId": "9a5d6d97-8983-4253-8095-b7d899e33ac8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2156683801],\n",
       " [2012373852],\n",
       " [1999931407],\n",
       " [2124861983],\n",
       " [171007782],\n",
       " [2060919843],\n",
       " [2000297003],\n",
       " [1974143004],\n",
       " [1972193616],\n",
       " [2943415491]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the paper titles based on their index\n",
    "id2details(df, I, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbxFKF-DZxg0",
    "outputId": "d78cdc03-41f6-469d-bf67-8f32001a7415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehdi/repos/vector_engine\n"
     ]
    }
   ],
   "source": [
    "# Define project base directory\n",
    "# Change the index from 1 to 0 if you run this on Google Colab\n",
    "project_dir = Path('notebooks').resolve().parents[1]\n",
    "print(project_dir)\n",
    "\n",
    "# Serialise index and store it as a pickle\n",
    "with open(f\"{project_dir}/models/faiss_index4.pickle\", \"wb\") as h:\n",
    "    pickle.dump(faiss.serialize_index(index), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtSC6oDDjtMA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "001-vector-search.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15c5bbc768db41e4bc06c9405539091c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e1408cddd284bc4a4b5484be0561991": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e9c24c8488b431fb88a0d045d85b700": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Batches: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15c5bbc768db41e4bc06c9405539091c",
      "max": 264,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9c22552944b4e2dafe1f98170665293",
      "value": 264
     }
    },
    "7a7e927567024c578b33b15000d5e531": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e9c24c8488b431fb88a0d045d85b700",
       "IPY_MODEL_7aaf8a423e7f48bbac24d6970ed4dfe9"
      ],
      "layout": "IPY_MODEL_da5011a6565e45e2b5d0b37634498648"
     }
    },
    "7aaf8a423e7f48bbac24d6970ed4dfe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f1cd9dbb4b742ab8d78e073fb9b0f90",
      "placeholder": "​",
      "style": "IPY_MODEL_1e1408cddd284bc4a4b5484be0561991",
      "value": " 264/264 [00:31&lt;00:00,  8.30it/s]"
     }
    },
    "7f1cd9dbb4b742ab8d78e073fb9b0f90": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da5011a6565e45e2b5d0b37634498648": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9c22552944b4e2dafe1f98170665293": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
